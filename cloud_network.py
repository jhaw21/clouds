from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten
import pickle
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import os
from keras.models import load_model
import cv2 as cv

os.environ['KMP_DUPLICATE_LIB_OK']='True'

input_shape = (112,112,3)
nClasses = 10
 
def createModel():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))
    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
 
    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
 
    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
 
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.25))
    
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nClasses, activation='softmax'))
 
    return model

fin = open("trainLabels.pickle", "rb")
trainLabels = np.array(pickle.load(fin))
fin.close()

fin = open("testLabels.pickle", "rb")
testLabels = np.array(pickle.load(fin))
fin.close()

LOAD_MODEL = False
if LOAD_MODEL:
    model1 = load_model("cnn.h5")
    # fin = open("history.pickle", "rb")
    # history2 = pickle.load(fin)
    # fin.close() 
else:
    model1 = createModel()
    print(model1.summary())
    batch_size = 128
    epochs = 150
    model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

    fin = open("test_images.pickle", "rb")
    test_images = np.array(pickle.load(fin))
    fin.close()

    fin = open("train_images.pickle", "rb")
    train_images = np.array(pickle.load(fin))
    fin.close()

    print(np.shape(testLabels))
    print(np.shape(test_images))
    print(testLabels[0])

    datagen = ImageDataGenerator(
            zoom_range=0.2, # randomly zoom into images
            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
            horizontal_flip=True,  # randomly flip images
            vertical_flip=False)  # randomly flip images

    # Fit the model on the batches generated by datagen.flow().
    history2 = model1.fit_generator(datagen.flow(train_images, trainLabels, batch_size=batch_size),
                                steps_per_epoch=int(np.ceil(train_images.shape[0] / float(batch_size))),
                                epochs=epochs,
                                validation_data=(test_images, testLabels),
                                )
    model1.save("cnn.h5") 

    fout = open("history.pickle", "wb")
    pickle.dump(history2, fout)
    fout.close()

#index=93
tsk = []
murph = []
for index in range(0,100):
    img = cv.imread("train/cloud_%04d.png"%index)
    img = np.reshape(img,[1,112,112,3])

    clouds = {'altostratus':0, 'cumulus':1, 'cumulonimbus':2, 'altocumulus':3,
            'stratocumulus':4, 'cirrostratus':5, 'stratus':6, 'nimbostratus':7,
            'cirrus':8, 'cirrocumulus':9}
    iCloud = {value: key for key, value in clouds.items()}

    hola = model1.predict_classes(img)[0]
    ciao = iCloud[hola]
    bonjour = iCloud[np.where(trainLabels[index] == 1)[0][0]]
    if ciao != bonjour:
        tsk.append(index)
        murph.append(np.where(trainLabels[index] == 1)[0][0])

print(tsk)
print(sorted(murph))
print(len(murph))
#hi = model1.evaluate(test_images, testLabels)
#print(hi)

# # Loss Curves
# plt.figure(figsize=[8,6])
# plt.plot(history2.history['loss'],'r',linewidth=3.0)
# plt.plot(history2.history['val_loss'],'b',linewidth=3.0)
# plt.legend(['Training loss', 'Validation Loss'],fontsize=18)
# plt.xlabel('Epochs ',fontsize=16)
# plt.ylabel('Loss',fontsize=16)
# plt.title('Loss Curves',fontsize=16)
 
# # Accuracy Curves
# plt.figure(figsize=[8,6])
# plt.plot(history2.history['acc'],'r',linewidth=3.0)
# plt.plot(history2.history['val_acc'],'b',linewidth=3.0)
# plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)
# plt.xlabel('Epochs ',fontsize=16)
# plt.ylabel('Accuracy',fontsize=16)
# plt.title('Accuracy Curves',fontsize=16)

#history = model1.fit(train_images, trainLabels, batch_size=batch_size, epochs=epochs, verbose=1,
#                   validation_data=(test_images, testLabels))

#model1.evaluate(test_images, testLabels)
